{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "PyTorch version:[1.7.0].\nThis notebook use [cuda:0].\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "%config InlineBackend.figure_format='retina'\n",
    "print (\"PyTorch version:[%s].\"%(torch.__version__))\n",
    "\n",
    "# Device Configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (\"This notebook use [%s].\"%(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "FEATURES=28\n",
    "NUM_HEADS=4\n",
    "BATCH_SIZE = 256\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Preparing dataset done!\n"
    }
   ],
   "source": [
    "# MNIST dataset\n",
    "mnist_train = datasets.MNIST(root='./data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = datasets.MNIST(root='./data/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
    "\n",
    "print(\"Preparing dataset done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](./figures/MHA/fig02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled Dot-Product Attention\n",
    "\n",
    "$$\n",
    "\n",
    "Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(torch.Size([1, 28, 28]), torch.Size([1, 28, 28]))"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        dk = key.size()[-1]\n",
    "        scores = query.matmul(key.transpose(-2, -1)) / np.sqrt(dk)\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)  \n",
    "        attention = torch.softmax(scores, dim=-1)\n",
    "        out = attention.matmul(value)\n",
    "        return out, attention\n",
    "\n",
    "y = torch.rand(1, 28, 28)\n",
    "out = ScaledDotProductAttention()(y, y, y)\n",
    "out[0].shape, out[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Head Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, features, num_heads, bias=True, dropout_ratio = 0.1, activation=F.relu_):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert features % num_heads == 0, f'\"features\"(features) should be divisible by \"head_num\"(num_heads)'\n",
    "        \n",
    "        self.features = features\n",
    "        self.num_heads = num_heads\n",
    "        self.head_features = features // num_heads\n",
    "        self.bias = bias\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "        self.act = activation\n",
    "\n",
    "        self.wq = nn.Linear(features, features, bias=bias)\n",
    "        self.wk = nn.Linear(features, features, bias=bias)\n",
    "        self.wv = nn.Linear(features, features, bias=bias)\n",
    "\n",
    "        self.fc = nn.Linear(features, features, bias=bias)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        # batch_size, num_heads, seq_len, head_features\n",
    "        x = x.reshape(batch_size, -1, self.num_heads, self.head_features)\n",
    "        return x.permute([0, 2, 1, 3])\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        # q, k, v: (batch_size, seq_len, features)\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention, attention_weights = ScaledDotProductAttention()(q, k, v, mask)\n",
    "\n",
    "        scaled_attention = scaled_attention.permute([0, 2, 1, 3])\n",
    "\n",
    "        scaled_attention = scaled_attention.reshape(batch_size, -1, self.features)\n",
    "\n",
    "        out = self.fc(scaled_attention)\n",
    "        if self.act is not None:\n",
    "            out = self.act(out)\n",
    "\n",
    "        return out, attention_weights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Encoder\n",
    "\n",
    "![image](./figures/ViT/fig01.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, features, fffeatures):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "\n",
    "        layer_list = [\n",
    "            nn.Linear(features, fffeatures),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(fffeatures, features)\n",
    "        ]\n",
    "\n",
    "        self.net = nn.Sequential(*layer_list)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, features, num_heads, fffeatures, dropout_rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(features, num_heads)\n",
    "        self.ffn = FeedForwardNetwork(features, fffeatures)\n",
    "\n",
    "        self.attnlayernorm = nn.LayerNorm(features)\n",
    "        self.ffnlayernorm = nn.LayerNorm(features)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  \n",
    "        attn_output = self.dropout(attn_output)\n",
    "        out = self.attnlayernorm(x + attn_output)  \n",
    "\n",
    "        ffn_output = self.ffn(out)  \n",
    "        ffn_output = self.dropout(ffn_output)\n",
    "        out = self.ffnlayernorm(out + ffn_output)  \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, features=28, num_heads=4, num_layers=6, fffeatures=512, dropout_ratio=0.1, num_classes=10, init_weight=\"he\", init_bias=\"zero\"):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.init_weight = init_weight\n",
    "        self.init_bias = init_bias\n",
    "        \n",
    "        \n",
    "        self.transformer_encoder = nn.Sequential(*[EncoderLayer(features, num_heads, fffeatures, dropout_ratio) for _ in range(num_layers)])\n",
    "        self.linear = nn.Linear(fffeatures, num_classes)\n",
    "\n",
    "        self.init_params()\n",
    "        \n",
    "    def init_params(self):\n",
    "        \n",
    "        init_weight_method = {\n",
    "        \"he\": nn.init.kaiming_normal_, \n",
    "        \"xavier\": nn.init.xavier_normal_\n",
    "        }\n",
    "        assert self.init_weight in init_weight_method.keys(), f'Select the weight initialization method in {list(init_weight_method.keys())}'\n",
    "        \n",
    "        init_bias_method = {\n",
    "            \"zero\": nn.init.zeros_, \n",
    "            \"uniform\": nn.init.uniform_\n",
    "        }\n",
    "        assert self.init_bias in init_bias_method.keys(), f'Select the bias initialization method in {list(init_bias_method.keys())}'\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init_weight_method[self.init_weight](m.weight)\n",
    "                init_bias_method[self.init_bias](m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        x, _ = self.mha(x, x, x)\n",
    "        return self.net(x)\n",
    "\n",
    "model = Model(FEATURES, NUM_HEADS).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of Total Parameters: 200,562\n"
    }
   ],
   "source": [
    "total_params = 0\n",
    "for param_name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        total_params += len(param.reshape(-1))\n",
    "print(f\"Number of Total Parameters: {total_params:,d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define help function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eval(model, data_iter, batch_size):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch_img, batch_lab in data_iter:\n",
    "            X = batch_img.view(-1, 1, 28, 28).to(device)\n",
    "            Y = batch_lab.to(device)\n",
    "            y_pred = model(X)\n",
    "            _, predicted = torch.max(y_pred.data, 1)\n",
    "            correct += (predicted == Y).sum().item()\n",
    "            total += batch_img.size(0)\n",
    "        val_acc = (100 * correct / total)\n",
    "        model.train()\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Phase\n",
    "print_every = 1\n",
    "print(\"Start training !\")\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_val_sum = 0\n",
    "    for batch_img, batch_lab in train_iter:\n",
    "\n",
    "        X = batch_img.view(-1, 1, 28, 28).to(device)\n",
    "        Y = batch_lab.to(device)\n",
    "        \n",
    "        # Inference & Calculate los\n",
    "        y_pred = model.forward(X)\n",
    "        loss = criterion(y_pred, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_val_sum += loss\n",
    "        \n",
    "    if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
    "        # accr_val = M.test(x_test, y_test, batch_size)\n",
    "        loss_val_avg = loss_val_sum / len(train_iter)\n",
    "        accr_val = test_eval(model, test_iter, BATCH_SIZE)\n",
    "        print(f\"epoch:[{epoch+1}/{EPOCHS}] cost:[{loss_val_avg:.3f}] test_accuracy:[{accr_val:.3f}]\")\n",
    "print(\"Training Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_sample = 64\n",
    "sample_indices = np.random.choice(len(mnist_test.targets), n_sample, replace=False)\n",
    "test_x = mnist_test.data[sample_indices]\n",
    "test_y = mnist_test.targets[sample_indices]\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    y_pred = model.forward(test_x.view(-1, 1, 28, 28).type(torch.float).to(device))\n",
    "    model.train()\n",
    "\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for idx in range(n_sample):\n",
    "    plt.subplot(8, 8, idx+1)\n",
    "    plt.imshow(test_x[idx], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Predict: {y_pred[idx]}, Label: {test_y[idx]}\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1608641568065",
   "display_name": "Python 3.7.9 64-bit ('tc': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}